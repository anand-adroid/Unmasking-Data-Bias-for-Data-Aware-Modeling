
In the advancement of healthcare machine learning (HML) models, the quest for unbiased predictive outcomes is not just technical—it's fundamentally ethical. Despite substantial strides facilitated by HML, the specter of unfairness looms, propelled by the dual engines of data and algorithmic biases.The Impossibility Theorem in Fairness asserts that models with perfect performance and optimal fairness are simultaneously unattainable except special cases. Nevertheless, we can endeavor to find an optimal balance—a perfect trade-off tailored to specific domains. In the realm of healthcare machine learning (HML), this balance is not just about mitigating algorithmic bias; it's also about understanding and rectifying data biases. Researchers often face the colossal task of sifting through extensive data documentation to unearth task-specific anomalies. To streamline this process, we present the Datasheet for MIMIC IV v2.0. This resource empowers researchers to discern and address data inconsistencies, guides the selection of sensitive attributes for fairness assessments, and facilitates the creation of robust, just, and data-conscious HML models. More than a mere inventory, the datasheet provides comprehensive insights into the database's 

## Contents
- [Motivation](MOTIVATION.md)
- [Composition](COMPOSITION.md)
- [Collection Process](COLLECTION_PROCESS.md)
- [Preprocessing/cleaning/labeling](PREPROCESSING_CLEANING_LABELING.md)
- [Uses](USES.md)
- [Distribution](DISTRIBUTION.md)
- [Maintenance](MAINTENANCE.md)
- [Analysis - Risk Prediction Tasks](ANALYSIS_RISK_PREDICTION_TASKS.md)

This datasheet, inspired by [Gebru et al., 2021](https://dl.acm.org/doi/pdf/10.1145/3458723) template, has been adapted for the intricacies of Clinical Research Databases (CRDs) and enriched to offer a thorough understanding of the data's fabric and its implications for HML tasks.


For more details, please refer to the complete MIMIC IV v2.0 datasheet provided in this repository.
